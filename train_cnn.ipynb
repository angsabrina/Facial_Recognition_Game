{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kevin\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import pandas as pd\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.optimizers import Adadelta\n",
    "from keras.utils import np_utils\n",
    "# from keras.regularizers import l2, activity_l2\n",
    "import numpy\n",
    "import csv\n",
    "import scipy.misc\n",
    "import scipy\n",
    "from scipy import ndimage\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.Session(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'E:/GT/DeepLearning_Hackathon/images/all/fer2013'\n",
    "data = pd.read_csv(path + '/fer2013.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion</th>\n",
       "      <th>pixels</th>\n",
       "      <th>Usage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>151 150 147 155 148 133 111 140 170 174 182 15...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>231 212 156 164 174 138 161 173 182 200 106 38...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   emotion                                             pixels     Usage\n",
       "0        0  70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...  Training\n",
       "1        0  151 150 147 155 148 133 111 140 170 174 182 15...  Training\n",
       "2        2  231 212 156 164 174 138 161 173 182 200 106 38...  Training\n",
       "3        4  24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...  Training\n",
       "4        6  4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...  Training"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping= {0:'Angry', 1:'Disgust', 2:'Fear', 3:'Happy', 4:'Sad', 5:'Surprise', 6:'Neutral'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2304"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data.pixels[0].split(\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion</th>\n",
       "      <th>pixels</th>\n",
       "      <th>Usage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[[[70], [80], [82], [72], [58], [58], [60], [6...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>[[[151], [150], [147], [155], [148], [133], [1...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[[[231], [212], [156], [164], [174], [138], [1...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>[[[24], [32], [36], [30], [32], [23], [19], [2...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>[[[4], [0], [0], [0], [0], [0], [0], [0], [0],...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   emotion                                             pixels     Usage\n",
       "0        0  [[[70], [80], [82], [72], [58], [58], [60], [6...  Training\n",
       "1        0  [[[151], [150], [147], [155], [148], [133], [1...  Training\n",
       "2        2  [[[231], [212], [156], [164], [174], [138], [1...  Training\n",
       "3        4  [[[24], [32], [36], [30], [32], [23], [19], [2...  Training\n",
       "4        6  [[[4], [0], [0], [0], [0], [0], [0], [0], [0],...  Training"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_pixels = []\n",
    "for i in data.pixels.tolist():\n",
    "    new_pixels.append(np.asarray([int(x) for x in i.split(\" \")]).reshape((48,48,1)))\n",
    "data.pixels = new_pixels\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Activation, Convolution2D, Dropout, Conv2D\n",
    "from keras.layers import AveragePooling2D, BatchNormalization\n",
    "from keras.layers import GlobalAveragePooling2D\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import SeparableConv2D\n",
    "from keras import layers\n",
    "from keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_CNN(input_shape, num_classes):\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Convolution2D(filters=16, kernel_size=(7, 7), padding='same',\n",
    "                            name='image_array', input_shape=input_shape))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Convolution2D(filters=16, kernel_size=(7, 7), padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(AveragePooling2D(pool_size=(2, 2), padding='same'))\n",
    "    model.add(Dropout(.5))\n",
    "\n",
    "    model.add(Convolution2D(filters=32, kernel_size=(5, 5), padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Convolution2D(filters=32, kernel_size=(5, 5), padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(AveragePooling2D(pool_size=(2, 2), padding='same'))\n",
    "    model.add(Dropout(.5))\n",
    "\n",
    "    model.add(Convolution2D(filters=64, kernel_size=(3, 3), padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Convolution2D(filters=64, kernel_size=(3, 3), padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(AveragePooling2D(pool_size=(2, 2), padding='same'))\n",
    "    model.add(Dropout(.5))\n",
    "\n",
    "    model.add(Convolution2D(filters=128, kernel_size=(3, 3), padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Convolution2D(filters=128, kernel_size=(3, 3), padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(AveragePooling2D(pool_size=(2, 2), padding='same'))\n",
    "    model.add(Dropout(.5))\n",
    "\n",
    "    model.add(Convolution2D(filters=256, kernel_size=(3, 3), padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Convolution2D(\n",
    "        filters=num_classes, kernel_size=(3, 3), padding='same'))\n",
    "    model.add(GlobalAveragePooling2D())\n",
    "    model.add(Activation('softmax', name='predictions'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = simple_CNN((48,48,1), 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "28709/28709 [==============================] - 28s 972us/step - loss: 1.8175 - acc: 0.2711\n",
      "Epoch 2/15\n",
      "28709/28709 [==============================] - 24s 852us/step - loss: 1.6077 - acc: 0.3686\n",
      "Epoch 3/15\n",
      "28709/28709 [==============================] - 24s 853us/step - loss: 1.5261 - acc: 0.4056\n",
      "Epoch 4/15\n",
      "28709/28709 [==============================] - 25s 855us/step - loss: 1.4651 - acc: 0.4286\n",
      "Epoch 5/15\n",
      "28709/28709 [==============================] - 25s 855us/step - loss: 1.4177 - acc: 0.4495\n",
      "Epoch 6/15\n",
      "28709/28709 [==============================] - 25s 857us/step - loss: 1.3890 - acc: 0.4658\n",
      "Epoch 7/15\n",
      "28709/28709 [==============================] - 25s 858us/step - loss: 1.3705 - acc: 0.4687\n",
      "Epoch 8/15\n",
      "28709/28709 [==============================] - 25s 856us/step - loss: 1.3514 - acc: 0.4790\n",
      "Epoch 9/15\n",
      "28709/28709 [==============================] - 25s 857us/step - loss: 1.3376 - acc: 0.4858\n",
      "Epoch 10/15\n",
      "28709/28709 [==============================] - 25s 857us/step - loss: 1.3126 - acc: 0.4962\n",
      "Epoch 11/15\n",
      "28709/28709 [==============================] - 25s 857us/step - loss: 1.3050 - acc: 0.5010\n",
      "Epoch 12/15\n",
      "28709/28709 [==============================] - 25s 857us/step - loss: 1.2896 - acc: 0.5044\n",
      "Epoch 13/15\n",
      "28709/28709 [==============================] - 24s 852us/step - loss: 1.2838 - acc: 0.5068\n",
      "Epoch 14/15\n",
      "28709/28709 [==============================] - 24s 853us/step - loss: 1.2733 - acc: 0.5146\n",
      "Epoch 15/15\n",
      "28709/28709 [==============================] - 25s 855us/step - loss: 1.2660 - acc: 0.5187\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x239992449b0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "trainX = data.pixels[:int(0.8 * len(data.pixels))].tolist()\n",
    "trainY = data.emotion[:int(0.8 * len(data.emotion))].tolist()\n",
    "\n",
    "testX = data.pixels[int(0.8 * len(data.pixels)):].tolist()\n",
    "testY = data.emotion[int(0.8 * len(data.emotion)):].tolist()\n",
    "\n",
    "# type(trainX)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(np.array(trainX), to_categorical(trainY), epochs=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save model and weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"model.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capture images and classify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 faces!\n",
      "x, y = (472, 231)\n",
      "w, h = (333, 333)\n",
      "x+w =  805\n",
      "y+h =  564\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import sys\n",
    "\n",
    "# Get user supplied values\n",
    "# imagePath = sys.argv[1]\n",
    "imagePath = 'images/kevin-happy-new.jpg'\n",
    "cascPath = \"haarcascade_frontalface_default.xml\"\n",
    "\n",
    "# Create the haar cascade\n",
    "faceCascade = cv2.CascadeClassifier(cascPath)\n",
    "\n",
    "# Read the image\n",
    "image = cv2.imread(imagePath)\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "\n",
    "# Detect faces in the image\n",
    "faces = faceCascade.detectMultiScale(\n",
    "    gray,\n",
    "    scaleFactor=1.1,\n",
    "    minNeighbors=5,\n",
    "    minSize=(30, 30),\n",
    ")\n",
    "\n",
    "print(\"Found {0} faces!\".format(len(faces)))\n",
    "\n",
    "# Draw a rectangle around the faces\n",
    "for (x, y, w, h) in faces:\n",
    "    print ('x, y =', (x, y))\n",
    "    print ('w, h =', (w, h))\n",
    "    cv2.rectangle(image, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "    print ('x+w = ', x+w)\n",
    "    print ('y+h = ', y+h)\n",
    "#     cv2.imwrite('images/kevin-happy-found.jpg', img[x:x+w, y:y+h])\n",
    "\n",
    "cv2.imshow(\"img\", image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "img = cv2.imread('images/kevin-happy-new.jpg')\n",
    "crop_img = img[y:y+h, x:x+w]\n",
    "cv2.imwrite('images/kevin-happy-new-cropped.jpg', crop_img)\n",
    "cv2.imshow(\"cropped\", crop_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:\\GT\\DeepLearning_Hackathon\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[152, 151, 149, ..., 111, 107, 106],\n",
       "       [151, 150, 150, ..., 107, 103, 101],\n",
       "       [150, 150, 149, ..., 105, 101,  99],\n",
       "       ...,\n",
       "       [ 45,  45,  44, ...,  64,  64,  65],\n",
       "       [ 45,  45,  46, ...,  66,  66,  66],\n",
       "       [ 44,  45,  46, ...,  66,  66,  67]], dtype=uint8)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import PIL\n",
    "\n",
    "print (os.getcwd())\n",
    "image = cv2.imread('images/kevin-happy-new-cropped.jpg')\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "gray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(\"img\", gray)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "img = cv2.resize(gray, (48, 48), PIL.Image.ANTIALIAS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48, 48)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('img', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[146, 146, 144, ..., 114, 116, 109],\n",
       "       [149, 144, 144, ..., 118, 115, 104],\n",
       "       [145, 143, 142, ..., 115, 107, 111],\n",
       "       ...,\n",
       "       [ 42,  41,  40, ...,  56,  56,  58],\n",
       "       [ 42,  41,  41, ...,  58,  63,  63],\n",
       "       [ 44,  44,  47, ...,  62,  66,  63]], dtype=uint8)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(img.reshape(1, 48, 48, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7.36504188e-03, 1.12034024e-04, 5.67797618e-03, 7.92389691e-01,\n",
       "        1.06053473e-02, 6.52102893e-03, 1.77328840e-01]], dtype=float32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'Angry',\n",
       " 1: 'Disgust',\n",
       " 2: 'Fear',\n",
       " 3: 'Happy',\n",
       " 4: 'Sad',\n",
       " 5: 'Surprise',\n",
       " 6: 'Neutral'}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_face = np.argmax(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_answer = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.923896908760071"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds[0][correct_answer] * 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
