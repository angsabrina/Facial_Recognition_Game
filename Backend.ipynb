{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kevin\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import pandas as pd\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.optimizers import Adadelta\n",
    "from keras.utils import np_utils\n",
    "import numpy\n",
    "import csv\n",
    "import scipy.misc\n",
    "import scipy\n",
    "from scipy import ndimage\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import model_from_json\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.Session(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n"
     ]
    }
   ],
   "source": [
    "json_file = open('model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"model.h5\")\n",
    "print(\"Loaded model from disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.models.Sequential at 0x2042accda58>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 faces!\n",
      "x, y = (508, 204)\n",
      "w, h = (310, 310)\n",
      "x+w =  818\n",
      "y+h =  514\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import sys\n",
    "\n",
    "# Get user supplied values\n",
    "# imagePath = sys.argv[1]\n",
    "imagePath = 'images/kevin-sad-new.jpg'\n",
    "cascPath = \"haarcascade_frontalface_default.xml\"\n",
    "\n",
    "# Create the haar cascade\n",
    "faceCascade = cv2.CascadeClassifier(cascPath)\n",
    "\n",
    "# Read the image\n",
    "image = cv2.imread(imagePath)\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "\n",
    "# Detect faces in the image\n",
    "faces = faceCascade.detectMultiScale(\n",
    "    gray,\n",
    "    scaleFactor=1.1,\n",
    "    minNeighbors=5,\n",
    "    minSize=(30, 30),\n",
    ")\n",
    "\n",
    "print(\"Found {0} faces!\".format(len(faces)))\n",
    "\n",
    "# Draw a rectangle around the faces\n",
    "for (x, y, w, h) in faces:\n",
    "    print ('x, y =', (x, y))\n",
    "    print ('w, h =', (w, h))\n",
    "    cv2.rectangle(image, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "    print ('x+w = ', x+w)\n",
    "    print ('y+h = ', y+h)\n",
    "#     cv2.imwrite('images/kevin-happy-found.jpg', img[x:x+w, y:y+h])\n",
    "\n",
    "cv2.imshow(\"img\", image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "img = cv2.imread('images/kevin-sad-new.jpg')\n",
    "crop_img = img[y:y+h, x:x+w]\n",
    "cv2.imwrite('images/kevin-sad-new-cropped.jpg', crop_img)\n",
    "cv2.imshow(\"cropped\", crop_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:\\GT\\DeepLearning_Hackathon\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[220, 219, 216, ..., 127, 129, 129],\n",
       "       [220, 219, 216, ..., 126, 129, 130],\n",
       "       [221, 218, 215, ..., 127, 130, 132],\n",
       "       ...,\n",
       "       [ 65,  32,  51, ...,  53,  55,  56],\n",
       "       [ 57,  31,  48, ...,  54,  56,  56],\n",
       "       [ 55,  33,  48, ...,  55,  56,  57]], dtype=uint8)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import PIL\n",
    "\n",
    "print (os.getcwd())\n",
    "image = cv2.imread('images/kevin-sad-new-cropped.jpg')\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "gray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cv2.imshow(\"img\", gray)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "img = cv2.resize(gray, (48, 48), PIL.Image.ANTIALIAS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cv2.imshow('img', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds = loaded_model.predict(img.reshape(1, 48, 48, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.08941597, 0.00169639, 0.03757307, 0.00144573, 0.09324053,\n",
       "        0.00492798, 0.7717003 ]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mapping = {0: 'Angry',\n",
    " 1: 'Disgust',\n",
    " 2: 'Fear',\n",
    " 3: 'Happy',\n",
    " 4: 'Sad',\n",
    " 5: 'Surprise',\n",
    " 6: 'Neutral'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "correct_answer = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9324052929878235"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds[0][correct_answer] * 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unit tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kevin\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'keras.models.Sequential'>\n",
      "Found 1 faces!\n",
      "Score =  0.9187986701726913\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.optimizers import Adadelta\n",
    "from keras.utils import np_utils\n",
    "import scipy.misc\n",
    "import scipy\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import model_from_json\n",
    "import cv2\n",
    "import sys\n",
    "import PIL\n",
    "from PIL import Image\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.Session(config=config)\n",
    "\n",
    "def load(model_loc, weights_loc):\n",
    "    json_file = open(model_loc, 'r')\n",
    "    loaded_model_json = json_file.read()\n",
    "    json_file.close()\n",
    "    loaded_model = model_from_json(loaded_model_json)\n",
    "    # load weights into new model\n",
    "    loaded_model.load_weights(weights_loc)\n",
    "    print(type(loaded_model))\n",
    "    return loaded_model\n",
    "\n",
    "\n",
    "def bounding_boxes(image_loc):\n",
    "    imagePath = image_loc\n",
    "    cascPath = \"haarcascade_frontalface_default.xml\"\n",
    "\n",
    "    # Create the haar cascade\n",
    "    faceCascade = cv2.CascadeClassifier(cascPath)\n",
    "\n",
    "    # Read the image\n",
    "    image = cv2.imread(imagePath)\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "\n",
    "    # Detect faces in the image\n",
    "    faces = faceCascade.detectMultiScale(\n",
    "        gray,\n",
    "        scaleFactor=1.1,\n",
    "        minNeighbors=5,\n",
    "        minSize=(30, 30),\n",
    "    )\n",
    "\n",
    "    print(\"Found {0} faces!\".format(len(faces)))\n",
    "\n",
    "    # Draw a rectangle around the faces\n",
    "    for (x, y, w, h) in faces:\n",
    "        cv2.rectangle(image, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "\n",
    "    cv2.imshow(\"img\", image)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    return x, y, w, h\n",
    "\n",
    "def crop(x, y, w, h):\n",
    "    img = cv2.imread('images/kevin-sad-new.jpg')\n",
    "    crop_img = img[y:y+h, x:x+w]\n",
    "    cv2.imwrite('images/kevin-sad-new-cropped.jpg', crop_img)\n",
    "    cv2.imshow(\"cropped\", crop_img)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    return crop_img\n",
    "\n",
    "def gray(cropped_img):\n",
    "    gray = cv2.cvtColor(cropped_img, cv2.COLOR_BGR2GRAY)\n",
    "    img = cv2.resize(gray, (48, 48), PIL.Image.ANTIALIAS)\n",
    "    return img\n",
    "\n",
    "\n",
    "\n",
    "loaded_model = load('model.json', 'model.h5')\n",
    "x, y, w, h = bounding_boxes('images/kevin-sad-new.jpg')\n",
    "cropped_img = crop(x, y, w, h)\n",
    "img = gray(cropped_img)\n",
    "\n",
    "preds = loaded_model.predict(img.reshape(1, 48, 48, 1))\n",
    "mapping = {0: 'Angry',\n",
    " 1: 'Disgust',\n",
    " 2: 'Fear',\n",
    " 3: 'Happy',\n",
    " 4: 'Sad',\n",
    " 5: 'Surprise',\n",
    " 6: 'Neutral'}\n",
    "\n",
    "## have the correct answer beforehand\n",
    "correct_answer = 4\n",
    "\n",
    "score = preds[0][correct_answer] * 10\n",
    "print ('Score = ', score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(loaded_model) == keras.models.Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import unittest \n",
    "\n",
    "class MyTest(unittest.TestCase):\n",
    "    def test(self):\n",
    "        self.assertEqual(type(load('model.json', 'model.h5')), keras.models.Sequential)\n",
    "tester = MyTest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'keras.models.Sequential'>\n"
     ]
    }
   ],
   "source": [
    "tester.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
